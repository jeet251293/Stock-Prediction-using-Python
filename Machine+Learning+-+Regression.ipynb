{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "### It takes continuous data and figure out a best fit line (y=mx+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages 'quandl', 'sklearn', 'numpy' & 'pandas' from Anaconda Prompt\n",
    "### Note: quandl is used to access dataset (stock data). Numpy is used to access arrays\n",
    "### Preprocessing is used to scale the features (The goal is to get the features between -1 and 1). Also improve the accuracy and processing speed\n",
    "### Cross validation is used to create training and testing samples\n",
    "### SVM can also be used to do regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "import math, datetime\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=quandl.get('WIKI/GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
      "Date                                                                   \n",
      "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
      "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
      "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
      "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
      "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
      "\n",
      "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
      "Date                                                                   \n",
      "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
      "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
      "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
      "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
      "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
      "\n",
      "            Adj. Volume  \n",
      "Date                     \n",
      "2004-08-19   44659000.0  \n",
      "2004-08-20   22834300.0  \n",
      "2004-08-23   18256100.0  \n",
      "2004-08-24   15247300.0  \n",
      "2004-08-25    9188600.0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the above columns are called features\n",
    "### Note: Adj is basically the prices when the stock splits\n",
    "\n",
    "### Now all the features in the dataset are not relevant to us, so we only use selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Open  Adj. High   Adj. Low  Adj. Close  Adj. Volume\n",
      "Date                                                                \n",
      "2004-08-19  50.159839  52.191109  48.128568   50.322842   44659000.0\n",
      "2004-08-20  50.661387  54.708881  50.405597   54.322689   22834300.0\n",
      "2004-08-23  55.551482  56.915693  54.693835   54.869377   18256100.0\n",
      "2004-08-24  55.792225  55.972783  51.945350   52.597363   15247300.0\n",
      "2004-08-25  52.542193  54.167209  52.100830   53.164113    9188600.0\n"
     ]
    }
   ],
   "source": [
    "print (df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we define relationship amongst features\n",
    "\n",
    "### Percent Volatility= (High-Low)/Low\n",
    "\n",
    "### Percent Change= (new-old)/old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['HL_PCT']=(df['Adj. High']-df['Adj. Low'])/df['Adj. Low']*100.0\n",
    "\n",
    "df['PCT_change']=(df['Adj. Close']-df['Adj. Open'])/df['Adj. Open']*100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we define the only features that are relevant to us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[['Adj. Close','HL_PCT','PCT_change','Adj. Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adj. Close    HL_PCT  PCT_change  Adj. Volume\n",
      "Date                                                      \n",
      "2004-08-19    50.322842  8.441017    0.324968   44659000.0\n",
      "2004-08-20    54.322689  8.537313    7.227007   22834300.0\n",
      "2004-08-23    54.869377  4.062357   -1.227880   18256100.0\n",
      "2004-08-24    52.597363  7.753210   -5.726357   15247300.0\n",
      "2004-08-25    53.164113  3.966115    1.183658    9188600.0\n",
      "2004-08-26    54.122070  3.143512    2.820391    7094800.0\n",
      "2004-08-27    53.239345  2.772258   -1.803885    6211700.0\n",
      "2004-08-30    51.162935  3.411430   -3.106003    5196700.0\n",
      "2004-08-31    51.343492  1.517228    0.048866    4917800.0\n",
      "2004-09-01    50.280210  3.310926   -2.385589    9138200.0\n",
      "2004-09-02    50.912161  3.466748    2.442224   15118600.0\n",
      "2004-09-03    50.159839  2.436569   -0.931154    5152400.0\n",
      "2004-09-07    50.947269  2.399357    0.564301    5847500.0\n",
      "2004-09-08    51.308384  2.517413    1.548541    4985600.0\n",
      "2004-09-09    51.313400  1.693069   -0.185366    4061700.0\n",
      "2004-09-10    52.828075  5.192498    3.804080    8698800.0\n",
      "2004-09-13    53.916435  1.831674    0.815905    7844100.0\n",
      "2004-09-14    55.917612  4.878734    3.769546   10828900.0\n",
      "2004-09-15    56.173402  3.656987    1.302460   10713000.0\n",
      "2004-09-16    57.161452  3.716973    1.450952    9266300.0\n",
      "2004-09-17    58.926902  3.469837    2.683097    9472500.0\n",
      "2004-09-20    59.864797  4.136336    2.060710   10628700.0\n",
      "2004-09-21    59.102444  2.476385   -1.963394    7228700.0\n",
      "2004-09-22    59.373280  2.448421    0.791826    7581200.0\n",
      "2004-09-23    60.597057  4.794052    1.666106    8535600.0\n",
      "2004-09-24    60.100525  3.623914   -0.942382    9123400.0\n",
      "2004-09-27    59.313094  2.614601   -1.087320    7066100.0\n",
      "2004-09-28    63.626409  5.981200    4.713165   16929000.0\n",
      "2004-09-29    65.742942  6.963479    3.595985   30516400.0\n",
      "2004-09-30    65.000651  2.558140   -0.230179   13758000.0\n",
      "...                 ...       ...         ...          ...\n",
      "2017-12-06  1032.720000  2.390403    1.593673    1369276.0\n",
      "2017-12-07  1044.570000  1.309689    0.820408    1437448.0\n",
      "2017-12-08  1049.380000  1.009695   -0.231030    1479665.0\n",
      "2017-12-11  1051.970000  1.137800    0.081818    1096997.0\n",
      "2017-12-12  1048.770000  1.687291   -0.117143    1684977.0\n",
      "2017-12-13  1051.390000  0.850389   -0.065584    1369580.0\n",
      "2017-12-14  1057.470000  1.279423    0.187591    1531504.0\n",
      "2017-12-15  1072.000000  1.430067    0.772716    3080738.0\n",
      "2017-12-18  1085.090000  1.506021    0.802638    1482768.0\n",
      "2017-12-19  1079.780000  1.184403   -0.299163    1287930.0\n",
      "2017-12-20  1073.560000  1.181920   -0.680901    1429035.0\n",
      "2017-12-21  1070.850000  0.797007   -0.422172    1211012.0\n",
      "2017-12-22  1068.860000  0.382151   -0.106542     860800.0\n",
      "2017-12-26  1065.850000  0.965390   -0.261080     914574.0\n",
      "2017-12-27  1060.200000  0.934447   -0.600038    1027634.0\n",
      "2017-12-28  1055.950000  1.087926   -0.593081     982285.0\n",
      "2017-12-29  1053.400000  0.508217   -0.198012    1156357.0\n",
      "2018-01-02  1073.210000  2.180395    1.917343    1555809.0\n",
      "2018-01-03  1091.520000  2.111922    1.637909    1550593.0\n",
      "2018-01-04  1095.760000  0.897410   -0.121230    1289293.0\n",
      "2018-01-05  1110.290000  1.069160    0.619874    1493389.0\n",
      "2018-01-08  1114.210000  0.825225    0.288929    1148958.0\n",
      "2018-01-09  1112.790000  0.924021   -0.505168    1335995.0\n",
      "2018-01-10  1110.140000  0.797116    0.283650    1027781.0\n",
      "2018-01-11  1111.880000  0.756453   -0.038658    1102461.0\n",
      "2018-01-12  1130.650000  2.101967    1.851185    1914460.0\n",
      "2018-01-16  1130.700000  1.972201   -0.842753    1783881.0\n",
      "2018-01-17  1139.100000  1.409002    0.241121    1353097.0\n",
      "2018-01-18  1135.970000  1.434466   -0.296660    1333633.0\n",
      "2018-01-19  1143.500000  0.996026    0.480655    1418376.0\n",
      "\n",
      "[3378 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To solve the problem of missing values, I usually replace these with -99999 instead of NaN. This will ensure that the data is not lost and at the same time it will be treated as an outlier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-99999,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign 'Adj. Close' column to a variable so that we can make changes in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forcast_col='Adj. Close'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression is basically used for forcasting  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic: I'm taking 0.0081 or 0.81% of the length of all the rows within the dataframe. Each row in the dataFrame is representation of a day in the life of the stock. So for example if the stock has been trading for 365 days, there will be 365 rows in the dataFrame. 1% of 365 is 3.65 days which is then rounded up by the math.ceil function to 4 days. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "forcast_out=math.ceil(0.0081*len(df))\n",
    "print(forcast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=df[forcast_col].shift(-forcast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Adj. Close    HL_PCT  PCT_change  Adj. Volume        label\n",
      "Date                                                                   \n",
      "2004-08-19    50.322842  8.441017    0.324968   44659000.0    65.742942\n",
      "2004-08-20    54.322689  8.537313    7.227007   22834300.0    65.000651\n",
      "2004-08-23    54.869377  4.062357   -1.227880   18256100.0    66.495265\n",
      "2004-08-24    52.597363  7.753210   -5.726357   15247300.0    67.739104\n",
      "2004-08-25    53.164113  3.966115    1.183658    9188600.0    69.399229\n",
      "2004-08-26    54.122070  3.143512    2.820391    7094800.0    68.752232\n",
      "2004-08-27    53.239345  2.772258   -1.803885    6211700.0    69.639972\n",
      "2004-08-30    51.162935  3.411430   -3.106003    5196700.0    69.078238\n",
      "2004-08-31    51.343492  1.517228    0.048866    4917800.0    67.839414\n",
      "2004-09-01    50.280210  3.310926   -2.385589    9138200.0    68.912727\n",
      "2004-09-02    50.912161  3.466748    2.442224   15118600.0    70.668146\n",
      "2004-09-03    50.159839  2.436569   -0.931154    5152400.0    71.219849\n",
      "2004-09-07    50.947269  2.399357    0.564301    5847500.0    72.278116\n",
      "2004-09-08    51.308384  2.517413    1.548541    4985600.0    74.810934\n",
      "2004-09-09    51.313400  1.693069   -0.185366    4061700.0    74.199045\n",
      "2004-09-10    52.828075  5.192498    3.804080    8698800.0    70.462511\n",
      "2004-09-13    53.916435  1.831674    0.815905    7844100.0    74.921275\n",
      "2004-09-14    55.917612  4.878734    3.769546   10828900.0    86.481962\n",
      "2004-09-15    56.173402  3.656987    1.302460   10713000.0    93.990139\n",
      "2004-09-16    57.161452  3.716973    1.450952    9266300.0    91.181468\n",
      "2004-09-17    58.926902  3.469837    2.683097    9472500.0    93.272925\n",
      "2004-09-20    59.864797  4.136336    2.060710   10628700.0    96.949273\n",
      "2004-09-21    59.102444  2.476385   -1.963394    7228700.0    95.615155\n",
      "2004-09-22    59.373280  2.448421    0.791826    7581200.0    98.318500\n",
      "2004-09-23    60.597057  4.794052    1.666106    8535600.0    97.736704\n",
      "2004-09-24    60.100525  3.623914   -0.942382    9123400.0    96.131750\n",
      "2004-09-27    59.313094  2.614601   -1.087320    7066100.0    92.635958\n",
      "2004-09-28    63.626409  5.981200    4.713165   16929000.0    84.937193\n",
      "2004-09-29    65.742942  6.963479    3.595985   30516400.0    86.542147\n",
      "2004-09-30    65.000651  2.558140   -0.230179   13758000.0    84.611187\n",
      "...                 ...       ...         ...          ...          ...\n",
      "2017-12-06  1032.720000  2.390403    1.593673    1369276.0  1135.970000\n",
      "2017-12-07  1044.570000  1.309689    0.820408    1437448.0  1143.500000\n",
      "2017-12-08  1049.380000  1.009695   -0.231030    1479665.0          NaN\n",
      "2017-12-11  1051.970000  1.137800    0.081818    1096997.0          NaN\n",
      "2017-12-12  1048.770000  1.687291   -0.117143    1684977.0          NaN\n",
      "2017-12-13  1051.390000  0.850389   -0.065584    1369580.0          NaN\n",
      "2017-12-14  1057.470000  1.279423    0.187591    1531504.0          NaN\n",
      "2017-12-15  1072.000000  1.430067    0.772716    3080738.0          NaN\n",
      "2017-12-18  1085.090000  1.506021    0.802638    1482768.0          NaN\n",
      "2017-12-19  1079.780000  1.184403   -0.299163    1287930.0          NaN\n",
      "2017-12-20  1073.560000  1.181920   -0.680901    1429035.0          NaN\n",
      "2017-12-21  1070.850000  0.797007   -0.422172    1211012.0          NaN\n",
      "2017-12-22  1068.860000  0.382151   -0.106542     860800.0          NaN\n",
      "2017-12-26  1065.850000  0.965390   -0.261080     914574.0          NaN\n",
      "2017-12-27  1060.200000  0.934447   -0.600038    1027634.0          NaN\n",
      "2017-12-28  1055.950000  1.087926   -0.593081     982285.0          NaN\n",
      "2017-12-29  1053.400000  0.508217   -0.198012    1156357.0          NaN\n",
      "2018-01-02  1073.210000  2.180395    1.917343    1555809.0          NaN\n",
      "2018-01-03  1091.520000  2.111922    1.637909    1550593.0          NaN\n",
      "2018-01-04  1095.760000  0.897410   -0.121230    1289293.0          NaN\n",
      "2018-01-05  1110.290000  1.069160    0.619874    1493389.0          NaN\n",
      "2018-01-08  1114.210000  0.825225    0.288929    1148958.0          NaN\n",
      "2018-01-09  1112.790000  0.924021   -0.505168    1335995.0          NaN\n",
      "2018-01-10  1110.140000  0.797116    0.283650    1027781.0          NaN\n",
      "2018-01-11  1111.880000  0.756453   -0.038658    1102461.0          NaN\n",
      "2018-01-12  1130.650000  2.101967    1.851185    1914460.0          NaN\n",
      "2018-01-16  1130.700000  1.972201   -0.842753    1783881.0          NaN\n",
      "2018-01-17  1139.100000  1.409002    0.241121    1353097.0          NaN\n",
      "2018-01-18  1135.970000  1.434466   -0.296660    1333633.0          NaN\n",
      "2018-01-19  1143.500000  0.996026    0.480655    1418376.0          NaN\n",
      "\n",
      "[3378 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this dataset, maybe we want to train our model to predict the price 0.81% into the future. Then, to train, we need historical data to grab values, and then use those values alongside whatever the price was 0.81% into the future (0.81% into the future as in 0.81% of the days of the entire dataset. We use .shift, which is a pandas method, which can take a column and literally shift it in a direction by a number we decide. Thus, we use this to make a new column, which is the price column shifted, giving us the future prices in the same rows as current price, volume to be trained against.\n",
    "\n",
    "### As we can now see the 29th row Adj. Close value is now 1st row's Label value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume  label\n",
      "Date                                                            \n",
      "2018-01-12     1130.65  2.101967    1.851185    1914460.0    NaN\n",
      "2018-01-16     1130.70  1.972201   -0.842753    1783881.0    NaN\n",
      "2018-01-17     1139.10  1.409002    0.241121    1353097.0    NaN\n",
      "2018-01-18     1135.97  1.434466   -0.296660    1333633.0    NaN\n",
      "2018-01-19     1143.50  0.996026    0.480655    1418376.0    NaN\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since I shifted the values up by 28 rows there are going be null values at the end of the label column. So I'll drop these null values now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Adj. Close    HL_PCT  PCT_change  Adj. Volume    label\n",
      "Date                                                              \n",
      "2017-12-01     1025.07  2.000197   -0.518240    1850541.0  1130.65\n",
      "2017-12-04     1011.87  2.191792   -1.549912    1896325.0  1130.70\n",
      "2017-12-05     1019.60  3.428047    0.851640    1927802.0  1139.10\n",
      "2017-12-06     1032.72  2.390403    1.593673    1369276.0  1135.97\n",
      "2017-12-07     1044.57  1.309689    0.820408    1437448.0  1143.50\n"
     ]
    }
   ],
   "source": [
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=np.array(df.drop(['label'],1))\n",
    "y=np.array(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are taking all features in X and labels in y. Therefore we need to drop label column from data frame so that there are only features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LinearRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "accuracy=clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.981788342583\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above model is 98.17% accurate\n",
    "### For Linear Regression accuracy is squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
